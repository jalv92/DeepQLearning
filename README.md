# ğŸš€ DeepQLearning para Trading AlgorÃ­tmico ğŸ“ˆ

![Version](https://img.shields.io/badge/version-1.1.21-blue)
![Python](https://img.shields.io/badge/Python-3.9%2B-brightgreen)
![NinjaTrader](https://img.shields.io/badge/NinjaTrader-8-orange)

## ğŸŒŸ VisiÃ³n General

DeepQLearning es un sistema avanzado de trading algorÃ­tmico que combina aprendizaje por refuerzo profundo con la plataforma NinjaTrader 8. El sistema utiliza datos de mercado en tiempo real para generar seÃ±ales de trading, las ejecuta automÃ¡ticamente y aprende de los resultados reales para mejorar continuamente.

```mermaid
graph TD
    A[NinjaTrader/DataFeeder.cs] <--Datos de mercado--> B[DeepQ.py]
    A <--SeÃ±ales de trading--> B
    A <--Resultados de operaciones--> B
    B --> C[(dqn_learning.db)]
    D[HFT_TheStrat_ML] --> A
    A --> E[Operaciones de mercado]
```

## ğŸ§  CaracterÃ­sticas Principales

- ğŸ¤– **Aprendizaje por Refuerzo Profundo**: Utiliza Stable-Baselines3 con el algoritmo PPO
- ğŸ”„ **RetroalimentaciÃ³n Bidireccional**: IntegraciÃ³n completa entre Python y NinjaTrader
- ğŸ’¡ **Sistema de Consenso**: Combina mÃºltiples fuentes de seÃ±ales para reducir falsos positivos
- ğŸ“Š **AdaptaciÃ³n Continua**: Aprende y mejora con cada operaciÃ³n realizada
- ğŸ›¡ï¸ **GestiÃ³n de Riesgo Integrada**: Utiliza estrategias ATM de NinjaTrader para control profesional del riesgo
- ğŸ“š **Persistencia de Conocimiento**: Almacena experiencias en SQLite para aprendizaje a largo plazo

## ğŸ“‹ Componentes del Sistema

### ğŸ DeepQ.py

El cerebro del sistema. Implementa un agente de aprendizaje por refuerzo que:

- Recibe datos de mercado vÃ­a TCP
- Procesa los datos usando tÃ©cnicas de ventana mÃ³vil
- Genera seÃ±ales de trading con niveles de confianza
- Almacena experiencias en la base de datos
- Aprende de los resultados reales de las operaciones

### ğŸ“Š DataFeeder.cs

Una estrategia para NinjaTrader 8 que:

- EnvÃ­a datos de mercado a DeepQ.py
- Recibe y evalÃºa seÃ±ales de trading
- Implementa un sistema de votaciÃ³n con el indicador HFT_TheStrat_ML
- Ejecuta operaciones usando estrategias ATM nativas
- EnvÃ­a resultados de operaciones de vuelta a DeepQ.py

### ğŸ§ª Sistema de Recompensas HÃ­brido

Un enfoque innovador que:

- Comienza con recompensas simuladas basadas en movimientos de precio
- Gradualmente incorpora recompensas reales basadas en P&L
- Utiliza un factor de ponderaciÃ³n adaptativo (alpha) que evoluciona con el tiempo
- Normaliza las ganancias/pÃ©rdidas a un rango consistente de recompensas

## ğŸ› ï¸ InstalaciÃ³n y ConfiguraciÃ³n

### Requisitos Previos

- Python 3.9 o superior
- NinjaTrader 8
- Dependencias Python (ver `requirements.txt`)

### ConfiguraciÃ³n de NinjaTrader

1. **Preparar Plantillas ATM**:
   - Crea dos plantillas: "ATM-LONG" y "ATM-SHORT" en NinjaTrader
   - Configura niveles apropiados de stop loss y take profit

2. **Importar Componentes**:
   - Descomprime e importa `NT8/ML_Predator.zip` (indicador)
   - Descomprime e importa `NT8/DataFeeder.zip` (estrategia)
   - Compila los NinjaScripts (Build > Compile)

3. **Configurar DataFeeder**:
   - Aplica la estrategia a un grÃ¡fico del instrumento deseado
   - Configura parÃ¡metros:
     - `DefaultQuantity`: Cantidad de contratos
     - `MaxDailyTrades`: LÃ­mite diario de operaciones
     - `RequireConsensus`: Preferiblemente "true"
     - `MinConfidenceThreshold`: Entre 0.6-0.7

### InstalaciÃ³n de Python

```bash
# Instalar dependencias
pip install -r requirements.txt
```

## ğŸš€ EjecuciÃ³n del Sistema

1. **Iniciar NinjaTrader y DataFeeder**:
   - Abre NinjaTrader y asegÃºrate que DataFeeder estÃ© activo
   - Verifica que las plantillas ATM estÃ©n configuradas

2. **Ejecutar DeepQ.py**:
   ```bash
   python DeepQ.py
   ```
   - Configura el tamaÃ±o de la ventana de lag si es necesario
   - Espera a que se acumulen suficientes datos

3. **Monitoreo**:
   - Observa la consola de Python para ver seÃ±ales emitidas
   - Verifica la pestaÃ±a "Output" en NinjaTrader para confirmaciÃ³n de operaciones
   - Supervisa el rendimiento en el grÃ¡fico de NinjaTrader

## ğŸ“Š Flujo del Sistema

```mermaid
sequenceDiagram
    participant NT as NinjaTrader
    participant DF as DataFeeder.cs
    participant DQ as DeepQ.py
    participant DB as dqn_learning.db
    
    NT->>DF: Datos de mercado
    DF->>DQ: Datos vÃ­a TCP (puerto 5555)
    DQ->>DQ: Procesa datos y genera predicciÃ³n
    DQ->>DB: Almacena experiencia simulada
    DQ->>DF: EnvÃ­a seÃ±al de trading (puerto 5590)
    DF->>DF: EvalÃºa seÃ±al + TheStrat
    DF->>NT: Ejecuta operaciÃ³n (si procede)
    NT->>DF: Notifica resultado de operaciÃ³n
    DF->>DQ: EnvÃ­a resultado real (puerto 5591)
    DQ->>DB: Actualiza experiencia con recompensa real
    DQ->>DQ: Ajusta modelo con experiencia real
```

## ğŸ“ Notas importantes

- **Entrenamiento**: La base de datos `dqn_learning.db` almacena todas las experiencias y es persistente entre sesiones. No la elimines para conservar el conocimiento adquirido.
- **RecolecciÃ³n de Datos**: Al inicio de cada sesiÃ³n, el sistema necesita acumular suficientes datos (por defecto 3000 puntos) antes de comenzar a generar seÃ±ales.
- **Modo Playback**: El entrenamiento puede realizarse en modo playback de NinjaTrader para acumular experiencias sin riesgo real.
- **Intervalo entre Operaciones**: El sistema espera un mÃ­nimo de 2 minutos entre operaciones para evitar sobretrading.
- **LÃ­mite Diario**: Respeta el nÃºmero mÃ¡ximo de operaciones diarias configurado para gestionar el riesgo.

## ğŸ”§ Posibles Mejoras

- Implementar guardado/carga de modelos entrenados
- AÃ±adir soporte para mÃºltiples instrumentos simultÃ¡neos
- Implementar un panel de visualizaciÃ³n en tiempo real
- AÃ±adir notificaciones por correo electrÃ³nico o SMS
- Incorporar anÃ¡lisis de sentimiento de mercado

---

âš ï¸ **Aviso de Riesgo**: El trading algorÃ­tmico conlleva riesgos significativos. Este sistema debe ser utilizado con comprensiÃ³n completa de las operaciones que realiza y con capital que pueda permitirse perder. Pruebe exhaustivamente en entornos simulados antes de utilizar con dinero real.
